{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b06ccb0-ade4-4b30-b10f-06cd5dec1c96",
   "metadata": {},
   "source": [
    "# base\n",
    "\n",
    "> Abstract base class for managing background jobs with worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc462ef-5594-420a-beb4-217aee5e9341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp managers.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834064a-df38-49f4-a5fe-f63b867b8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a323f-0a83-4869-9048-0a82918e3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uuid\n",
    "import asyncio\n",
    "import multiprocessing\n",
    "import queue\n",
    "import threading\n",
    "import atexit\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional, List, Generic, TypeVar, Callable\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from fastcore.basics import patch\n",
    "\n",
    "from cjm_fasthtml_workers.core.config import WorkerConfig, RestartPolicy\n",
    "from cjm_fasthtml_workers.core.protocol import WorkerRequestType, WorkerResponseType\n",
    "from cjm_fasthtml_workers.extensions.protocols import (\n",
    "    PluginRegistryProtocol,\n",
    "    ResourceManagerProtocol,\n",
    "    EventBroadcasterProtocol,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac7c58-1b3d-4726-9e23-bfa0680be169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Set multiprocessing start method to 'spawn' for CUDA compatibility\n",
    "# Fork mode doesn't work with CUDA (cannot re-initialize CUDA in forked subprocess)\n",
    "try:\n",
    "    multiprocessing.set_start_method('spawn', force=True)\n",
    "except RuntimeError:\n",
    "    # Already set, ignore\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d6080a-1f4c-4b7f-9a33-ffcb6d349453",
   "metadata": {},
   "source": [
    "## BaseJob Dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be561648-fedb-48bf-831b-d4d4cfed6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class BaseJob:\n",
    "    \"\"\"Base class for all job types.\"\"\"\n",
    "    id: str  # Unique job identifier\n",
    "    plugin_id: str  # Plugin identifier for this job\n",
    "    status: str = \"pending\"  # Job status: pending, running, completed, failed, cancelled\n",
    "    created_at: str = field(default_factory=lambda: datetime.now().isoformat())  # ISO format timestamp\n",
    "    started_at: Optional[str] = None  # When job started executing\n",
    "    completed_at: Optional[str] = None  # When job finished\n",
    "    result: Optional[Dict[str, Any]] = None  # Job result data\n",
    "    error: Optional[str] = None  # Error message if failed\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)  # Additional job metadata\n",
    "    worker_pid: Optional[int] = None  # Process ID of worker handling this job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b0f90-a7ea-45f1-ab69-4d2920ce6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "JobType = TypeVar('JobType', bound=BaseJob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14008cd1-1b2b-48b8-9e53-b1cbe14c97b0",
   "metadata": {},
   "source": [
    "## BaseJobManager Class\n",
    "\n",
    "The `BaseJobManager` is an abstract base class that provides the core infrastructure for managing background jobs with worker processes. It handles:\n",
    "\n",
    "- Worker process lifecycle (start, restart, shutdown)\n",
    "- Job queuing and execution\n",
    "- Result monitoring\n",
    "- Resource management integration (optional)\n",
    "- Event broadcasting (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a4415-6fc2-41b1-af5f-404e5117034d",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nclass BaseJobManager(ABC, Generic[JobType]):\n    \"\"\"\n    Abstract base class for managing jobs using worker processes.\n\n    Features:\n    - Jobs processed sequentially in subprocess\n    - Plugin resources loaded once and reused\n    - True cancellation via subprocess termination\n    - Automatic worker restart based on policy\n    - Isolated worker process avoids duplicating web app initialization\n    - Optional streaming support for incremental results\n    - Optional dependency injection for plugin registry, resource manager, and event broadcaster\n    \"\"\"\n\n    def __init__(\n        self,\n        worker_type:str,  # Type identifier (e.g., \"transcription\", \"llm\", \"image-gen\")\n        category:Any,  # Plugin category this manager handles\n        supports_streaming:bool=False,  # Whether this manager supports streaming jobs\n        worker_config:Optional[WorkerConfig]=None,  # Worker configuration (uses defaults if None)\n        plugin_registry:Optional[PluginRegistryProtocol]=None,  # Optional plugin registry integration\n        resource_manager:Optional[ResourceManagerProtocol]=None,  # Optional resource manager integration\n        event_broadcaster:Optional[EventBroadcasterProtocol]=None,  # Optional SSE event broadcaster\n    ):\n        \"\"\"Initialize the job manager.\"\"\"\n        self.worker_type = worker_type\n        self.category = category\n        self.supports_streaming = supports_streaming\n        self.worker_config = worker_config or WorkerConfig()\n\n        self.jobs: Dict[str, JobType] = {}\n        self.results: Dict[str, Dict[str, Any]] = {}\n\n        # Multiprocessing queues for communication with worker\n        self.request_queue: Optional[multiprocessing.Queue] = None\n        self.result_queue: Optional[multiprocessing.Queue] = None\n        self.response_queue: Optional[multiprocessing.Queue] = None\n        self.worker_process: Optional[multiprocessing.Process] = None\n\n        # Thread for monitoring result queue\n        self.result_monitor_thread: Optional[threading.Thread] = None\n        self.monitor_running = False\n\n        # Optional integrations (dependency injection)\n        self.plugin_registry = plugin_registry\n        self.resource_manager = resource_manager\n        self.event_broadcaster = event_broadcaster\n\n        # Worker state tracking\n        self.current_plugin_name: Optional[str] = None\n        self.current_plugin_id: Optional[str] = None\n        self.current_config: Optional[Dict[str, Any]] = None\n\n        # Restart tracking\n        self.restart_count = 0\n        self.last_restart_time: Optional[float] = None\n\n        # Streaming support\n        self._stream_buffers: Dict[str, List[str]] = {}  # job_id -> chunks\n\n        # Worker will be started lazily on first job\n        # Register cleanup on exit\n        atexit.register(self.shutdown)"
  },
  {
   "cell_type": "markdown",
   "id": "3371144c-bacb-4c6a-b0b8-111c6fd93be9",
   "metadata": {},
   "source": [
    "## Abstract Methods\n",
    "\n",
    "Subclasses must implement these methods to customize job handling for their specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d90241-4c2b-47f7-b4d6-90c301199f02",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\n@abstractmethod\ndef create_job(\n    self:BaseJobManager,\n    plugin_id:str,  # Plugin unique identifier\n    **kwargs  # Domain-specific job parameters\n) -> JobType:  # Created job instance\n    \"\"\"Factory method for creating domain-specific jobs.\"\"\"\n    pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8f390-698f-4383-a690-f1414deea643",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\n@abstractmethod\ndef get_worker_entry_point(\n    self:BaseJobManager\n) -> Callable:  # Worker process entry point function\n    \"\"\"Return the worker process function for this manager.\"\"\"\n    pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a2ecb-5faf-426d-8a27-0fae494bf7f1",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\n@abstractmethod\ndef prepare_execute_request(\n    self:BaseJobManager,\n    job:JobType  # The job to prepare for execution\n) -> Dict[str, Any]:  # Dictionary of parameters for the worker execute request\n    \"\"\"Convert job to worker execute request parameters.\"\"\"\n    pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9040b2a5-c30e-4c58-bfe8-4feeab213754",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\n@abstractmethod\ndef extract_job_result(\n    self:BaseJobManager,\n    job:JobType,  # The job that was executed\n    result_data:Dict[str, Any]  # Raw result data from worker\n) -> Dict[str, Any]:  # Formatted result for storage\n    \"\"\"Extract and format job result from worker response.\"\"\"\n    pass"
  },
  {
   "cell_type": "markdown",
   "id": "p1rtl8nk2hk",
   "metadata": {},
   "source": [
    "## Hook Methods\n",
    "\n",
    "These methods provide extension points for subclasses to customize behavior without overriding core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muacnsieawk",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _extract_plugin_resource_identifier(\n    self:BaseJobManager,\n    config:Dict[str, Any]  # Plugin configuration dictionary\n) -> str:  # Plugin resource identifier string\n    \"\"\"Extract plugin resource identifier from plugin configuration.\"\"\"\n    # Try common configuration keys in order of preference\n    # Check 'resource_id' first, then fallback to common model-related keys for backward compatibility\n    return config.get('resource_id', \n                     config.get('model_id', \n                     config.get('model', \n                     config.get('model_name', 'unknown'))))"
  },
  {
   "cell_type": "markdown",
   "id": "a1td2taczao",
   "metadata": {},
   "source": [
    "This hook extracts a plugin resource identifier from the plugin configuration for resource tracking. The default implementation tries common keys (`resource_id`, `model_id`, `model`, `model_name`) but subclasses can override this to match their specific configuration structure.\n",
    "\n",
    "**Example override:**\n",
    "```python\n",
    "def _extract_plugin_resource_identifier(self, config):\n",
    "    # Custom logic for your plugin system\n",
    "    return config.get('resource_path', 'unknown')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ll4snizvura",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\nasync def _validate_resources(\n    self:BaseJobManager,\n    plugin_id:str,  # Plugin unique identifier\n    plugin_config:Dict[str, Any]  # Plugin configuration\n) -> Optional[str]:  # Error message if validation fails, None if successful\n    \"\"\"Validate resources before starting a job.\"\"\"\n    # Default implementation: no validation, always passes\n    return None"
  },
  {
   "cell_type": "markdown",
   "id": "lpfa6dtu90f",
   "metadata": {},
   "source": [
    "This hook allows you to implement custom validation before starting a job. Return `None` if validation passes, or an error message string if it fails.\n",
    "\n",
    "**Example override:**\n",
    "```python\n",
    "async def _validate_resources(self, plugin_id, plugin_config):\n",
    "    # Check if another job is already running\n",
    "    if self.worker_process and self.current_plugin_id:\n",
    "        return \"Another job is already running\"\n",
    "    \n",
    "    # Check GPU availability\n",
    "    if plugin_config.get('device') == 'cuda':\n",
    "        if not torch.cuda.is_available():\n",
    "            return \"CUDA not available\"\n",
    "    \n",
    "    return None  # Validation passed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4emfi7toa",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _on_job_completed(\n    self:BaseJobManager,\n    job_id:str  # ID of the completed job\n) -> None:\n    \"\"\"Hook called when a job completes successfully.\"\"\"\n    # Default implementation: no action\n    pass"
  },
  {
   "cell_type": "markdown",
   "id": "u22815ma2ad",
   "metadata": {},
   "source": [
    "This hook is called automatically when a job completes successfully. Use it to implement post-processing logic like saving results, sending notifications, or triggering follow-up tasks.\n",
    "\n",
    "**Example override:**\n",
    "```python\n",
    "def _on_job_completed(self, job_id):\n",
    "    job = self.get_job(job_id)\n",
    "    result = self.get_job_result(job_id)\n",
    "    \n",
    "    # Save result to disk\n",
    "    output_path = f\"results/{job_id}.json\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "    \n",
    "    # Track completion count\n",
    "    self.completed_count += 1\n",
    "    \n",
    "    print(f\"Job {job_id} completed and saved to {output_path}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed2ca3-8075-45d4-944c-dbb6874f0bbb",
   "metadata": {},
   "source": [
    "## Worker Lifecycle Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241210aa-91ff-4161-a2be-6037017220ed",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _start_worker(self:BaseJobManager):\n    \"\"\"Start the worker process and result monitor.\"\"\"\n    if self.worker_process and self.worker_process.is_alive():\n        return  # Already running\n\n    # Create fresh queues with configured sizes\n    self.request_queue = multiprocessing.Queue(maxsize=self.worker_config.request_queue_size)\n    self.result_queue = multiprocessing.Queue(maxsize=self.worker_config.result_queue_size)\n    self.response_queue = multiprocessing.Queue(maxsize=self.worker_config.response_queue_size)\n\n    # Start worker process using entry point from subclass\n    # Using spawn method ensures clean process isolation (required for CUDA)\n    worker_entry = self.get_worker_entry_point()\n    self.worker_process = multiprocessing.Process(\n        target=worker_entry,\n        args=(self.request_queue, self.result_queue, self.response_queue)\n    )\n    self.worker_process.start()\n\n    # Start result monitor thread\n    self.monitor_running = True\n    self.result_monitor_thread = threading.Thread(target=self._monitor_results, daemon=True)\n    self.result_monitor_thread.start()\n\n    # Register worker with resource manager if available\n    if self.resource_manager:\n        self.resource_manager.register_worker(\n            pid=self.worker_process.pid,\n            worker_type=self.worker_type\n        )\n\n    # Send initialization message with plugin configurations\n    self._init_worker()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f34a20-0408-48d9-a443-bac7c7c98bce",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _init_worker(self:BaseJobManager):\n    \"\"\"Send initialization message to worker with plugin configurations.\"\"\"\n    # Only send plugin configs if plugin registry is available\n    plugin_configs = {}\n    \n    if self.plugin_registry:\n        # Collect all plugin configurations from registry\n        plugins = self.plugin_registry.get_plugins_by_category(self.category)\n\n        for plugin_meta in plugins:\n            if plugin_meta.is_configured:\n                config = self.plugin_registry.load_plugin_config(plugin_meta.get_unique_id())\n                # Store by plugin name (not unique_id) since PluginManager uses name\n                plugin_configs[plugin_meta.name] = config\n\n    # Send init message with configs (worker discovers plugins)\n    self.request_queue.put({\n        'type': WorkerRequestType.INIT.value,\n        'plugin_configs': plugin_configs\n    })"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaff0df-3eff-4a56-8634-75cba3cb6d5a",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _restart_worker(self:BaseJobManager):\n    \"\"\"Restart the worker process after an error or cancellation.\"\"\"\n    # Track restart\n    self.restart_count += 1\n    self.last_restart_time = time.time()\n\n    # Unregister old worker from resource manager if available\n    if self.resource_manager and self.worker_process:\n        self.resource_manager.unregister_worker(self.worker_process.pid)\n\n    # Stop old worker if still alive\n    if self.worker_process and self.worker_process.is_alive():\n        self.worker_process.terminate()\n        self.worker_process.join(timeout=self.worker_config.shutdown_timeout_seconds)\n        if self.worker_process.is_alive():\n            self.worker_process.kill()\n\n    # Reset state\n    self.current_plugin_name = None\n    self.current_plugin_id = None\n    self.current_config = None\n\n    # Start new worker\n    self._start_worker()"
  },
  {
   "cell_type": "markdown",
   "id": "cac87cf3-0ffb-41fd-bf18-22276441f39c",
   "metadata": {},
   "source": [
    "## Result Monitoring and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452a981-68a8-42d7-b179-e5c89892e202",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _monitor_results(self:BaseJobManager):\n    \"\"\"Monitor the result queue in a background thread.\"\"\"\n    while self.monitor_running:\n        try:\n            result = self.result_queue.get(\n                timeout=self.worker_config.result_monitor_poll_interval_seconds\n            )\n\n            result_type = result.get('type')\n\n            if result_type == WorkerResponseType.RESULT.value:\n                self._handle_job_result(result)\n\n            elif result_type == WorkerResponseType.STREAM_CHUNK.value:\n                self._handle_stream_chunk(result)\n\n            elif result_type == WorkerResponseType.READY.value:\n                # Worker initialized successfully\n                pass  # Could log this if needed\n\n            elif result_type == WorkerResponseType.ERROR.value:\n                print(f\"Worker error: {result.get('error')}\")\n                # Worker had a fatal error, restart based on policy\n                self._handle_worker_error()\n\n        except queue.Empty:\n            continue\n        except (ValueError, OSError) as e:\n            # Queue was closed (happens during worker restart/cancellation)\n            # This is expected, just break out of the loop silently\n            if \"closed\" in str(e).lower():\n                break\n            # For other ValueError/OSError, log and continue\n            print(f\"Error in result monitor: {e}\")\n        except Exception as e:\n            print(f\"Error in result monitor: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54001a9d-233d-42e7-b91d-309dc5ad79ce",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _handle_job_result(\n    self:BaseJobManager, \n    result:Dict[str, Any]  # Result data from worker\n):\n    \"\"\"Handle a job result from the worker.\"\"\"\n    job_id = result['job_id']\n\n    if job_id not in self.jobs:\n        return\n\n    job = self.jobs[job_id]\n\n    if result['status'] == 'success':\n        job.status = 'completed'\n        job.result = self.extract_job_result(job, result.get('data', {}))\n        job.completed_at = datetime.now().isoformat()\n        self.results[job_id] = {\n            'status': 'success',\n            'data': job.result\n        }\n\n        # Update resource manager if available - job completed, worker now idle\n        if self.resource_manager and self.worker_process:\n            self.resource_manager.update_worker_state(\n                pid=self.worker_process.pid,\n                status=\"idle\"\n            )\n        \n        # Call completion hook for successful jobs\n        self._on_job_completed(job_id)\n\n    elif result['status'] == 'error':\n        job.status = 'failed'\n        job.error = result.get('error')\n        job.completed_at = datetime.now().isoformat()\n        self.results[job_id] = {\n            'status': 'error',\n            'error': result.get('error')\n        }\n\n        # Update resource manager if available - job failed, worker now idle\n        if self.resource_manager and self.worker_process:\n            self.resource_manager.update_worker_state(\n                pid=self.worker_process.pid,\n                status=\"idle\"\n            )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c95c9-36fc-482b-b338-fc46222dd701",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _handle_stream_chunk(\n    self:BaseJobManager, \n    chunk_data:Dict[str, Any]  # Chunk data from worker\n):\n    \"\"\"Handle a streaming chunk from the worker.\"\"\"\n    job_id = chunk_data.get('job_id')\n    chunk = chunk_data.get('chunk', '')\n    is_final = chunk_data.get('is_final', False)\n\n    if job_id not in self._stream_buffers:\n        self._stream_buffers[job_id] = []\n\n    self._stream_buffers[job_id].append(chunk)\n\n    # If final chunk, could trigger completion\n    # (actual completion still comes via RESULT message)\n    if is_final:\n        pass  # Placeholder for any final stream handling"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c488b-9fff-4053-9f38-d8e031908e09",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef _handle_worker_error(self:BaseJobManager):\n    \"\"\"Handle worker fatal error based on restart policy.\"\"\"\n    policy = self.worker_config.restart_policy\n\n    if policy == RestartPolicy.NEVER:\n        print(f\"[{self.worker_type}] Worker error - restart policy is NEVER, not restarting\")\n        return\n\n    if policy == RestartPolicy.ALWAYS or policy == RestartPolicy.BACKOFF:\n        if self.restart_count >= self.worker_config.max_restart_attempts:\n            print(f\"[{self.worker_type}] Max restart attempts ({self.worker_config.max_restart_attempts}) reached\")\n            return\n\n        if policy == RestartPolicy.BACKOFF:\n            # Calculate backoff delay\n            delay = min(\n                self.worker_config.restart_backoff_base_seconds * (2 ** self.restart_count),\n                self.worker_config.restart_backoff_max_seconds\n            )\n            print(f\"[{self.worker_type}] Restarting worker after {delay:.1f}s backoff...\")\n            time.sleep(delay)\n\n        self._restart_worker()"
  },
  {
   "cell_type": "markdown",
   "id": "fcb95b71-0eb6-4dc1-8dc7-93bd5346fb96",
   "metadata": {},
   "source": [
    "## Plugin Management Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a808bc-4116-4f3e-951a-69f8351b86fc",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef get_plugin_name(\n    self:BaseJobManager,\n    plugin_id:str  # Plugin unique identifier\n) -> Optional[str]:  # Plugin name or None\n    \"\"\"Get plugin name from plugin ID (requires plugin registry).\"\"\"\n    if not self.plugin_registry:\n        return None\n        \n    plugin_meta = self.plugin_registry.get_plugin(plugin_id)\n    if plugin_meta:\n        return plugin_meta.name\n    return None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e7fd5-9f8a-4d3b-bd82-7c1b6bad1627",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\nasync def unload_plugin(\n    self:BaseJobManager,\n    plugin_name:str  # Name of the plugin to unload\n) -> bool:  # True if successful, False otherwise\n    \"\"\"Unload a plugin from the worker to free resources.\"\"\"\n    if not self.worker_process or not self.worker_process.is_alive():\n        return False\n\n    # Send unload request\n    self.request_queue.put({\n        'type': WorkerRequestType.UNLOAD.value,\n        'plugin_name': plugin_name\n    })\n\n    # Wait for response (with timeout) from response queue\n    try:\n        response = self.response_queue.get(\n            timeout=self.worker_config.unload_timeout_seconds\n        )\n        if (response.get('type') == WorkerResponseType.RESPONSE.value and\n            response.get('request_type') == WorkerRequestType.UNLOAD.value):\n            if response.get('status') == 'success':\n                # Update local state\n                if self.current_plugin_name == plugin_name:\n                    self.current_plugin_name = None\n                    self.current_plugin_id = None\n                    self.current_config = None\n\n                # Update resource manager if available\n                if self.resource_manager and self.worker_process:\n                    self.resource_manager.update_worker_state(\n                        pid=self.worker_process.pid,\n                        plugin_name=None,\n                        plugin_id=None,\n                        loaded_plugin_resource=None,\n                        config=None,\n                        status=\"idle\"\n                    )\n\n                return True\n    except queue.Empty:\n        print(f\"Timeout waiting for unload response for {plugin_name}\")\n        return False\n\n    return False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fefd01-4c3d-457f-bfc1-0fa71d39fa67",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\nasync def reload_plugin(\n    self:BaseJobManager,\n    plugin_name:str,  # Name of the plugin to reload\n    config:Dict[str, Any]  # New configuration\n) -> bool:  # True if successful, False otherwise\n    \"\"\"Reload a plugin with new configuration.\"\"\"\n    print(f\"\\n[Manager] Reloading plugin: {plugin_name}\")\n    print(f\"[Manager] Device: {config.get('device', 'unknown')}\")\n\n    if not self.worker_process or not self.worker_process.is_alive():\n        print(\"[Manager] ✗ Worker process not alive\")\n        return False\n\n    # Send reload request\n    print(f\"[Manager] Sending reload request to worker PID {self.worker_process.pid}\")\n    self.request_queue.put({\n        'type': WorkerRequestType.RELOAD.value,\n        'plugin_name': plugin_name,\n        'config': config\n    })\n\n    # Wait for response (with timeout) from response queue\n    print(\"[Manager] Waiting for worker response...\")\n    try:\n        response = self.response_queue.get(\n            timeout=self.worker_config.reload_timeout_seconds\n        )\n        if (response.get('type') == WorkerResponseType.RESPONSE.value and\n            response.get('request_type') == WorkerRequestType.RELOAD.value):\n            if response.get('status') == 'success':\n                print(f\"[Manager] ✓ Reload successful\")\n                # Update local state\n                self.current_plugin_name = plugin_name\n                self.current_config = config\n\n                # Find plugin_id if registry available\n                if self.plugin_registry:\n                    for plugin_meta in self.plugin_registry.get_plugins_by_category(self.category):\n                        if plugin_meta.name == plugin_name:\n                            self.current_plugin_id = plugin_meta.get_unique_id()\n                            break\n\n                # Update resource manager if available\n                if self.resource_manager and self.worker_process:\n                    # Use helper method to extract plugin resource identifier\n                    resource_id = self._extract_plugin_resource_identifier(config)\n                    self.resource_manager.update_worker_state(\n                        pid=self.worker_process.pid,\n                        plugin_name=plugin_name,\n                        plugin_id=self.current_plugin_id,\n                        loaded_plugin_resource=resource_id,\n                        config=config,\n                        status=\"idle\"\n                    )\n                    print(f\"[Manager] Updated resource manager state for PID {self.worker_process.pid}\")\n\n                return True\n            else:\n                error_msg = response.get('error', 'Unknown error')\n                print(f\"[Manager] ✗ Reload failed: {error_msg}\")\n                return False\n    except queue.Empty:\n        print(f\"[Manager] ✗ Timeout waiting for reload response for {plugin_name}\")\n        return False\n\n    return False"
  },
  {
   "cell_type": "markdown",
   "id": "a9b59cae-f2e1-49e0-8e61-1a538ec06ba4",
   "metadata": {},
   "source": [
    "## Job Management Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7bd1a-e298-4fb3-8291-d7b282fb7b09",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\nasync def start_job(\n    self:BaseJobManager,\n    plugin_id:str,  # Plugin unique identifier\n    **kwargs  # Domain-specific job parameters\n) -> JobType:  # Created and started job\n    \"\"\"Start a new job.\"\"\"\n    # Ensure worker is running (lazy initialization)\n    if not self.worker_process or not self.worker_process.is_alive():\n        self._start_worker()\n\n    # Get plugin name (requires plugin registry)\n    plugin_name = self.get_plugin_name(plugin_id) if self.plugin_registry else None\n    if not plugin_name and self.plugin_registry:\n        raise ValueError(f\"Plugin {plugin_id} not found\")\n\n    # Get plugin config if registry available\n    plugin_config = None\n    if self.plugin_registry:\n        plugin_config = self.plugin_registry.load_plugin_config(plugin_id)\n    \n    # Call validation hook - subclasses can override to add custom validation\n    if plugin_config:\n        validation_error = await self._validate_resources(plugin_id, plugin_config)\n        if validation_error:\n            raise RuntimeError(f\"Resource validation failed: {validation_error}\")\n\n    # Create job\n    job = self.create_job(plugin_id=plugin_id, **kwargs)\n\n    # Store job\n    self.jobs[job.id] = job\n    job.status = \"running\"\n    job.started_at = datetime.now().isoformat()\n\n    # Store worker PID for resource tracking\n    if self.worker_process:\n        job.worker_pid = self.worker_process.pid\n\n    # Update manager state\n    self.current_plugin_name = plugin_name\n    self.current_plugin_id = plugin_id\n    self.current_config = plugin_config\n\n    # Update resource manager if available\n    if self.resource_manager and self.worker_process and plugin_config:\n        # Use helper method to extract plugin resource identifier\n        resource_id = self._extract_plugin_resource_identifier(plugin_config)\n        self.resource_manager.update_worker_state(\n            pid=self.worker_process.pid,\n            job_id=job.id,\n            plugin_name=plugin_name,\n            plugin_id=plugin_id,\n            loaded_plugin_resource=resource_id,\n            config=plugin_config,\n            status=\"running\"\n        )\n\n    # Send job to worker process\n    execute_params = self.prepare_execute_request(job)\n    self.request_queue.put({\n        'type': WorkerRequestType.EXECUTE.value,\n        'job_id': job.id,\n        'plugin_name': plugin_name,\n        **execute_params\n    })\n\n    # Broadcast job started event if broadcaster available\n    if self.event_broadcaster:\n        await self.event_broadcaster.broadcast(\n            f\"{self.worker_type}:started\",\n            {\"job_id\": job.id, \"plugin_id\": plugin_id}\n        )\n\n    return job"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb9b49-2886-40ec-8c3f-b8d3dc3f813b",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\nasync def cancel_job(\n    self:BaseJobManager,\n    job_id:str  # ID of the job to cancel\n) -> bool:  # True if cancellation successful\n    \"\"\"Cancel a running job by terminating the worker process.\"\"\"\n    if job_id not in self.jobs:\n        return False\n\n    job = self.jobs[job_id]\n\n    if job.status != \"running\":\n        return False\n\n    # Mark job as cancelled\n    job.status = \"cancelled\"\n    job.completed_at = datetime.now().isoformat()\n    self.results[job_id] = {\"status\": \"cancelled\"}\n\n    # Clean up old queues before terminating to avoid semaphore leaks\n    old_request_queue = self.request_queue\n    old_result_queue = self.result_queue\n    old_response_queue = self.response_queue\n\n    # Terminate the worker process (kills the running job)\n    if self.worker_process and self.worker_process.is_alive():\n        self.worker_process.terminate()\n        self.worker_process.join(timeout=self.worker_config.shutdown_timeout_seconds)\n        if self.worker_process.is_alive():\n            self.worker_process.kill()\n\n    # Close and join queues to clean up semaphores\n    for q in [old_request_queue, old_result_queue, old_response_queue]:\n        try:\n            if q:\n                q.close()\n                q.join_thread()\n        except:\n            pass\n\n    # Restart worker based on policy\n    if self.worker_config.restart_policy in [RestartPolicy.ON_CANCELLATION, RestartPolicy.ALWAYS, RestartPolicy.BACKOFF]:\n        self._restart_worker()\n\n    # Broadcast cancellation event if broadcaster available\n    if self.event_broadcaster:\n        await self.event_broadcaster.broadcast(\n            f\"{self.worker_type}:cancelled\",\n            {\"job_id\": job_id}\n        )\n\n    return True"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050083fd-1b71-408f-bf5a-f5a3c2e1ce39",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef get_job(\n    self:BaseJobManager,\n    job_id:str  # Unique job identifier\n) -> Optional[JobType]:  # Job object or None\n    \"\"\"Get a job by ID.\"\"\"\n    return self.jobs.get(job_id)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df1fb5-ee53-4703-a579-bb8b9d4133fe",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef get_all_jobs(\n    self:BaseJobManager\n) -> List[JobType]:  # List of all jobs\n    \"\"\"Get all jobs.\"\"\"\n    return list(self.jobs.values())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4da30-f8a7-42af-b3fa-6fdf6f8bf309",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef get_job_result(\n    self:BaseJobManager,\n    job_id:str  # Unique job identifier\n) -> Optional[Dict[str, Any]]:  # Job result or None\n    \"\"\"Get job result.\"\"\"\n    return self.results.get(job_id)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57e624a-339a-4d6e-ad1d-ee4d0f19775b",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef clear_completed_jobs(\n    self:BaseJobManager\n) -> int:  # Number of jobs cleared\n    \"\"\"Clear completed, failed, and cancelled jobs.\"\"\"\n    completed = [\n        job_id for job_id, job in self.jobs.items()\n        if job.status in ['completed', 'failed', 'cancelled']\n    ]\n\n    for job_id in completed:\n        del self.jobs[job_id]\n        if job_id in self.results:\n            del self.results[job_id]\n        if job_id in self._stream_buffers:\n            del self._stream_buffers[job_id]\n\n    return len(completed)"
  },
  {
   "cell_type": "markdown",
   "id": "bdc354f7-30bf-492d-a225-9cae89efb56d",
   "metadata": {},
   "source": [
    "## Utility Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2y8kfoud2pq",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "To use `BaseJobManager`, create a concrete subclass that implements the required abstract methods. Here's a minimal example structure:\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from cjm_fasthtml_workers.managers.base import BaseJobManager, BaseJob\n",
    "\n",
    "@dataclass\n",
    "class MyJob(BaseJob):\n",
    "    \"\"\"Custom job type with domain-specific fields.\"\"\"\n",
    "    input_text: str = \"\"\n",
    "    \n",
    "class MyJobManager(BaseJobManager[MyJob]):\n",
    "    \"\"\"Concrete job manager implementation.\"\"\"\n",
    "    \n",
    "    def create_job(self, plugin_id: str, **kwargs) -> MyJob:\n",
    "        \"\"\"Create a job instance.\"\"\"\n",
    "        return MyJob(\n",
    "            id=str(uuid.uuid4()),\n",
    "            plugin_id=plugin_id,\n",
    "            input_text=kwargs.get('input_text', '')\n",
    "        )\n",
    "    \n",
    "    def get_worker_entry_point(self) -> Callable:\n",
    "        \"\"\"Return the worker function.\"\"\"\n",
    "        return my_worker_process\n",
    "    \n",
    "    def prepare_execute_request(self, job: MyJob) -> Dict[str, Any]:\n",
    "        \"\"\"Convert job to execution parameters.\"\"\"\n",
    "        return {'text': job.input_text}\n",
    "    \n",
    "    def extract_job_result(self, job: MyJob, result_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Format the result.\"\"\"\n",
    "        return result_data\n",
    "\n",
    "# Create and use the manager\n",
    "manager = MyJobManager(\n",
    "    worker_type=\"text_processing\",\n",
    "    category=\"processing\",\n",
    "    worker_config=WorkerConfig()\n",
    ")\n",
    "\n",
    "# Start a job\n",
    "job = await manager.start_job(plugin_id=\"my-plugin\", input_text=\"Hello World\")\n",
    "```\n",
    "\n",
    "For a complete working example, see the `demo_app.py` file in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba744b-be6f-4e23-8583-2761b633f073",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\nasync def broadcast_event(\n    self:BaseJobManager,\n    event_type:str,  # Event type identifier\n    data:Dict[str, Any]  # Event data payload\n):\n    \"\"\"Broadcast an event to all connected SSE clients (requires event broadcaster).\"\"\"\n    if self.event_broadcaster:\n        await self.event_broadcaster.broadcast(event_type, data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebb74a4-c256-4c8a-8cdb-1cda133acb8b",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef check_streaming_support(\n    self:BaseJobManager,\n    plugin_id:str  # Plugin unique identifier\n) -> bool:  # True if streaming supported\n    \"\"\"Check if a plugin supports streaming.\"\"\"\n    # This would need to be implemented by subclasses if needed\n    # For now, return the manager's streaming support flag\n    return self.supports_streaming"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ca4b0-9eef-46fa-b482-5a7ea49ac4ce",
   "metadata": {},
   "outputs": [],
   "source": "#| export\n@patch\ndef shutdown(self:BaseJobManager):\n    \"\"\"Shutdown the manager and cleanup resources.\"\"\"\n    # Stop result monitor\n    self.monitor_running = False\n    if self.result_monitor_thread:\n        self.result_monitor_thread.join(timeout=2)\n\n    # Unregister worker from resource manager if available\n    if self.resource_manager and self.worker_process:\n        self.resource_manager.unregister_worker(self.worker_process.pid)\n\n    # Stop worker process\n    if self.worker_process and self.worker_process.is_alive():\n        # Try graceful shutdown first\n        try:\n            self.request_queue.put({'type': WorkerRequestType.STOP.value})\n            self.worker_process.join(timeout=self.worker_config.shutdown_timeout_seconds)\n        except:\n            pass\n\n        # Force kill if still alive\n        if self.worker_process.is_alive():\n            self.worker_process.terminate()\n            self.worker_process.join(timeout=2)\n            if self.worker_process.is_alive():\n                self.worker_process.kill()\n\n    # Clean up queues to prevent semaphore leaks\n    for q in [self.request_queue, self.result_queue, self.response_queue]:\n        try:\n            if q:\n                q.close()\n                q.join_thread()\n        except:\n            pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3904f94-2f41-43d7-9602-058f65732638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1f14e-301d-4f24-8477-f227f20d0e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c50ec8-f545-4709-b1c5-1051aaa63402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96390b9b-e249-45d2-9ab9-5fac93781b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762c6e8-5374-4f7c-8db9-c90e705f72d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
